# WARNING - Generated by {fusen} from dev/flat_ai_reporting.Rmd: do not edit by hand # nolint: line_length_linter.

#' Generate Plot Description with AI (Phase 3)
#'
#' This function implements Phase 3 of the AI reporting architecture.
#' It serves as the "Semantic Generator," combining structure and statistics
#' to prompt an LLM for a structured description.
#'
#' @param structure Metadata list returned by `extract_structure`.
#' @param stats Statistical profile returned by `profile_data`.
#' @param provider The LLM provider (e.g., "openai", "azure", "anthropic").
#' @param model The specific model to use.
#' @param max_tokens Maximum token limit for the response.
#' @return A list containing:
#'   \item{short_desc}{A concise, WCAG-compliant alt text string.}
#'   \item{long_desc}{A detailed analytical description of the visualization.}
#' @importFrom ellmer chat_openai chat_google_gemini chat_anthropic
#' @importFrom ellmer chat_ollama chat_azure_openai
#' @importFrom utils capture.output
#' @importFrom jsonlite fromJSON
#' @export
generate_description <- function(
  structure,
  stats,
  provider = NULL,
  model = NULL,
  max_tokens = 500
) {
  # Construct Context
  context_str <- paste0(
    "PLOT METADATA:\n",
    "Title: ",
    structure$labels$title,
    "\n",
    "Subtitle: ",
    structure$labels$subtitle,
    "\n",
    "Geoms: ",
    paste(unique(structure$geoms), collapse = ", "),
    "\n",
    "X Label: ",
    structure$labels$x,
    "\n",
    "Y Label: ",
    structure$labels$y,
    "\n\n",
    "STATISTICAL PROFILE:\n",
    "STATISTICAL PROFILE:\n",
    paste(capture.output(print(stats$distributions)), collapse = "\n"),
    "\n",
    "Correlations: ",
    paste(
      names(stats$correlations),
      unlist(stats$correlations),
      sep = ": ",
      collapse = ", "
    ),
    "\n"
  )

  system_prompt <- paste0(
    "You are the Senior Data Storyteller for UNHCR. ",
    "Your task is to translate statistical graphs into humanitarian narratives that inspire action.\n\n",
    "**1. CORE PHILOSOPHY: THE GRAPH IS EVIDENCE, NOT THE STORY.**\n",
    "- **Do NOT describe the chart visuals.** Never say 'The bar chart shows', 'The x-axis represents', or 'The blue line indicates'.\n",
    "- **Instead, describe the reality.** If the line goes up, write 'Displacement accelerated'. If the bar is huge, write 'The vast majority are concentrated in...'.\n\n",
    "**1. INSTITUTIONAL VOICE (UNHCR STYLE)**\n",
    "- **Tone:** Authoritative, Neutral (on conflict), Protection-Centric, and Action-Oriented.\n",
    "- **Semantics:** 'Illegal' -> 'Irregular'. 'Swarm' -> 'Large-scale movement'. 'Burden' -> 'Responsibility'.\n",
    "- **Privacy:** Suppress any counts < 5 (write 'a small number').\n\n",
    "**2. SEMANTIC FIREWALL (STRICT COMPLIANCE)**\n",
    "- **BANNED TERMS:** 'Illegal', 'Migrant' (when referring to refugees), 'Swarm', 'Flood', 'Burden', 'Beneficiaries'.\n",
    "- **MANDATORY REPLACEMENTS:**\n",
    "  * 'Illegal' -> 'Irregular movement' or 'Undocumented entry'.\n",
    "  * 'Swarm/Flood' -> 'Large-scale movement' or 'Influx'.\n",
    "  * 'Burden' -> 'Responsibility' or 'Pressure on services'.\n",
    "  * 'Beneficiaries' -> 'People we serve' or 'Refugees'.\n",
    "- **Acronyms:** Spell out on first use (e.g., 'Sexual and Gender-Based Violence (SGBV)').\n\n",
    "**3. ANALYTICAL HEURISTICS (INTERPRETING THE VISUALS)**\n",
    "- **Stable:** Change < 5% -> Describe as 'Remained relatively stable'.\n",
    "- **Significant:** Change > 10% -> Describe as 'Marked rise' or 'Significant increase'.\n",
    "- **Surge:** Change > 20% or sudden spike -> Describe as 'Surge' or 'Rapid escalation'.\n",
    "- **Concentration:** If top 3 groups > 50% -> Explicitly state: 'Displacement is highly concentrated among...'\n",
    "- **The Gap:** If there is a difference between Needs and Funding (or Arrivals vs. Returns), frame it as a 'Protection Gap'.'\n",
    "- **Privacy:** If any value is < 5 in a sensitive category (e.g., UASC), DO NOT state the number. Write 'A small number' or 'Fewer than five'.\n\n",
    "**4. NARRATIVE STRUCTURE (JSON OUTPUT)**\n",
    "Generate a strict JSON object with two keys:\n",
    "  * 'short_desc': WCAG-compliant alt text ('* [Chart Type] of [Variables] showing [Trend]*').\n",
    "  * 'long_desc': A 3-5 sentence narrative following this Story Arc:\n",
    "     (A) **The Headline (The Human Impact):** Start with the 'So What'. (e.g., 'Escalating violence has driven record displacement...').\n",
    "     (B) **The Evidence (The Data):** Weave the numbers in naturally to support the headline. (e.g., 'Arrivals doubled to [Number], straining capacity...').\n",
    "     (C) **The Context (The Driver):** Briefly mention the root cause if implied (conflict, policy).\n",
    "     (D) **The Call (The Implication):** Conclude with the need for support or the consequence of inaction."
  )


  prompt <- paste0(
    "Context:\n",
    context_str,
    "\n\n",
    "Task: Interpret this data to inspire action. \n",
    "Identify the 'Cause and Effect' relationship in the numbers. ",
    "Look at the data trends (spikes, gaps, concentrations) and explain what they mean for the people on the ground. \n",
    "Tell the story of what is happening to the people represented in this dataset. \n",
    "Apply strict UNHCR terminologies."
  )

  # Logic to select provider
  # (duplicated from generate_plot_story for now to adhere to modularity)
  if (is.null(provider)) {
    if (!is.na(Sys.getenv("AZURE_OPENAI_ENDPOINT", unset = NA_character_))) {
      provider <- "azure"
    } else if (!is.na(Sys.getenv("OPENAI_API_KEY", unset = NA_character_))) {
      provider <- "openai"
    } else if (!is.na(Sys.getenv("GEMINI_API_KEY", unset = NA_character_))) {
      provider <- "gemini"
    } else if (!is.na(Sys.getenv("ANTHROPIC_API_KEY", unset = NA_character_))) {
      provider <- "anthropic"
    } else {
      stop("No supported API key found.")
    }
  }

  provider <- tolower(provider)
  if (is.null(model)) {
    model <- switch(provider,
      openai = "gpt-4o-mini",
      gemini = "gemini-2.0-flash",
      anthropic = "claude-3-5-sonnet-latest",
      ollama = "deepseek-r1",
      azure = "gpt-4",
      stop("Invalid provider")
    )
  }

  chat <- switch(provider,
    openai = ellmer::chat_openai(
      model = model,
      system_prompt = system_prompt,
      type = "json_object"
    ),
    azure = {
      azure_key <- Sys.getenv("AZURE_OPENAI_API_KEY")
      azure_endpoint <- Sys.getenv("AZURE_OPENAI_ENDPOINT")
      azure_version <- Sys.getenv("AZURE_OPENAI_API_VERSION")
      ellmer::chat_azure_openai(
        system_prompt = system_prompt,
        model = model,
        api_version = azure_version,
        endpoint = azure_endpoint,
        api_key = azure_key,
        type = "json_object"
      )
    },
    gemini = ellmer::chat_google_gemini(
      model = model,
      system_prompt = system_prompt,
      api_key = Sys.getenv("GEMINI_API_KEY")
    ),
    anthropic = ellmer::chat_anthropic(
      model = model,
      system_prompt = system_prompt
    ),
    ollama = ellmer::chat_ollama(model = model, system_prompt = system_prompt),
    stop("Invalid provider")
  )

  response <- tryCatch(
    {
      chat$chat(prompt)
    },
    error = function(e) {
      paste("Error invoking AI provider:", e$message)
    }
  )

  # Parse JSON
  # Clean potential markdown code blocks if the model insists on adding them
  cleaned_json <- gsub("^```json\\s*|\\s*```$", "", response)

  tryCatch(
    {
      jsonlite::fromJSON(cleaned_json)
    },
    error = function(e) {
      list(short_desc = "Error parsing JSON", long_desc = response)
    }
  )
}
