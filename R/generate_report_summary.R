# WARNING - Generated by {fusen} from dev/flat_ai_reporting.Rmd: do not edit by hand # nolint: line_length_linter.

#' Generate Report Executive Summary
#'
#' Aggregates section summaries into a final executive summary.
#'
#' @param section_summaries A named list or character vector of section summaries.
#' @param country_name Name of the country.
#' @param year Year of the report.
#' @param provider Optional provider.
#' @param model Optional model.
#' @param max_tokens Max tokens.
#'
#' @return A character string containing the executive summary.
#' @export
#' @examples
#' \dontrun{
#' sections <- list("Population" = "Summary...", "Asylum" = "Summary...")
#' report_summary <- generate_report_summary(sections, "Colombia", 2022)
#' }
#' #generate_report_summary()
generate_report_summary <- function(section_summaries,
                                    country_name,
                                    year,
                                    provider = NULL,
                                    model = NULL,
                                    max_tokens = 400) {
  valid_summaries <- section_summaries[!is.na(section_summaries) &
                                         !grepl("AI summary.*skipped", section_summaries)]
  
  if (length(valid_summaries) == 0) {
    return("No AI executive summary available.")
  }
  
  combined_text <- paste(names(valid_summaries), ":\n", valid_summaries, collapse = "\n\n")
  
  system_prompt <- paste0(
    "You are an expert Protection Officer and Reporting Officer. ",
    "Create an executive summary for a humanitarian report based on the provided section summaries. ",
    "Highlight the most critical humanitarian needs, protection concerns, and key figures."
  )
  
  prompt <- paste0(
    "Country: ",
    country_name,
    "\n",
    "Year: ",
    year,
    "\n\n",
    "Section Summaries:\n",
    combined_text,
    "\n\n",
    "Write an executive summary for the report (approx ",
    max_tokens,
    " tokens)."
  )
  
  # Auto-detect provider if not specified
  if (is.null(provider)) {
    if (!is.na(Sys.getenv("OPENAI_API_KEY", unset = NA_character_))) {
      provider <- "openai"
    } else if (!is.na(Sys.getenv("GEMINI_API_KEY", unset = NA_character_))) {
      provider <- "gemini"
    } else if (!is.na(Sys.getenv("ANTHROPIC_API_KEY", unset = NA_character_))) {
      provider <- "anthropic"
    } else {
      return("Executive summary skipped (no API key).")
    }
  }
  
  provider <- tolower(provider)
  
  if (is.null(model)) {
    model <- switch(
      provider,
      openai = "gpt-4o-mini",
      gemini = "gemini-2.0-flash",
      anthropic = "claude-3-5-sonnet-latest",
      ollama = "phi3:latest",
      return("AI summary skipped (invalid provider).")
    )
  }
  
  chat <- tryCatch({
    switch(
      provider,
      openai = ellmer::chat_openai(model = model, system_prompt = system_prompt),
      gemini = ellmer::chat_google_gemini(system_prompt = system_prompt, model = model),
      anthropic = ellmer::chat_anthropic(model = model, system_prompt = system_prompt),
      ollama = ellmer::chat_ollama(model = model, system_prompt = system_prompt),
      stop("Invalid provider")
    )
  }, error = function(e)
    NULL)
  
  if (is.null(chat)) {
    return("AI summary failed (chat init).")
  }
  
  response <- tryCatch(
    chat$chat(prompt),
    error = function(e)
      "AI summary failed (API error)."
  )
  
  return(response)
}
