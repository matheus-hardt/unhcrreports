# WARNING - Generated by {fusen} from dev/flat_ai_reporting.Rmd: do not edit by hand # nolint: line_length_linter.

#' Generate Section Summary from Plot Stories
#'
#' Aggregates individual plot stories into a cohesive section summary.
#'
#' @param stories A character vector of stories generated from plots within the section.
#' @param section_name The title of the section (e.g., "Population Overview").
#' @param provider Optional provider (openai, gemini, anthropic). Auto-detected if NULL.
#' @param model Optional model name.
#' @param max_tokens Max tokens for the summary.
#'
#' @return A character string containing the section summary.
#' @export
#' @examples
#' \dontrun{
#' stories <- c("Story 1...", "Story 2...")
#' summary <- generate_section_summary(stories, "Population")
#' }
#' # generate_section_summary()
generate_section_summary <- function(stories,
                                     section_name,
                                     provider = NULL,
                                     model = NULL,
                                     max_tokens = 400) {
  # Graceful degradation if no stories or empty
  valid_stories <- stories[!is.na(stories) &
    stories != "" & !grepl("AI narrative generation skipped", stories)]

  if (length(valid_stories) == 0) {
    return(paste0("No AI insights available for ", section_name, "."))
  }

  combined_text <- paste(valid_stories, collapse = "\n\n")

  system_prompt <- paste0(
    "You are the Lead Editor for the UNHCR Global Report. ",
    "Your task is to synthesize multiple data insights into a cohesive narrative section that reads exactly like a chapter from the 'Global Trends' or 'Mid-Year Trends' report.\n\n",
    "### WRITING INSTRUCTIONS:\n",
    "- **Synthesis:** Do not just list the insights. Weave them together into a story of displacement, protection, or solutions.\n",
    "- **Context:** Connect specific data points to broader global themes (e.g., the impact of the Sudan crisis, the war in Ukraine, climate shocks).\n",
    "- **Language:** Use phrases like 'Behind these stark numbers...', 'The data reveals...', 'This constitutes a rise of...'.\n",
    "- **Focus:** Prioritize the magnitude of displacement, the burden on host communities, and the gap between needs and funding.\n"
  )

  prompt <- paste0(
    "Section Topic: ", section_name, "\n\n",
    "Input Data Narratives:\n", combined_text, "\n\n",
    "TASK: Write a cohesive section summary (approx ", max_tokens, " tokens) for this topic. ",
    "Ensure the tone is formal, humanitarian, and data-driven. Avoid bullet points; use prose."
  )

  # Auto-detect provider if not specified
  if (is.null(provider)) {
    if (!is.na(Sys.getenv("OPENAI_API_KEY", unset = NA_character_))) {
      provider <- "openai"
    } else if (!is.na(Sys.getenv("GEMINI_API_KEY", unset = NA_character_))) {
      provider <- "gemini"
    } else if (!is.na(Sys.getenv("ANTHROPIC_API_KEY", unset = NA_character_))) {
      provider <- "anthropic"
    } else {
      return(paste0("AI summary for ", section_name, " skipped (no API key)."))
    }
  }

  provider <- tolower(provider)

  if (is.null(model)) {
    model <- switch(provider,
      openai = "gpt-4o-mini",
      gemini = "gemini-2.0-flash",
      anthropic = "claude-3-5-sonnet-latest",
      ollama = "phi3:latest",
      return("AI summary skipped (invalid provider).")
    )
  }

  chat <- tryCatch(
    {
      switch(provider,
        openai = ellmer::chat_openai(model = model, system_prompt = system_prompt),
        gemini = ellmer::chat_google_gemini(system_prompt = system_prompt, model = model),
        anthropic = ellmer::chat_anthropic(model = model, system_prompt = system_prompt),
        ollama = ellmer::chat_ollama(model = model, system_prompt = system_prompt),
        stop("Invalid provider")
      )
    },
    error = function(e) {
      NULL
    }
  )

  if (is.null(chat)) {
    return("AI summary failed (chat init).")
  }

  response <- tryCatch(
    chat$chat(prompt),
    error = function(e) {
      "AI summary failed (API error)."
    }
  )

  return(response)
}
