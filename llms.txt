# {unhcrreports}: AI-Powered Humanitarian Reporting

> \[!IMPORTANT\] **Reporting Engine**: This package functions as the
> “Reporting Engine” for UNHCR statistics. It focuses on **orchestrating
> automated reports** by combining data, visualization, and AI
> narratives.
>
> **Graphics Source**: The standardized charts and maps used in these
> reports are built upon the
> [`unhcrviz`](https://github.com/Edouard-Legoupil/unhcrviz) package,
> which provides a high-level API over `unhcrthemes`.

`unhcrreports` automates the production of analytical reports (Country
and Regional) by: 1. **Retrieving Data**: Fetching the latest official
statistics via the `refugees` package. 2. **Visualizing Trends**:
Generating standardized plots using `unhcrviz`. 3. **Generating
Narratives**: Using Large Language Models (LLMs) to interpret data and
write context-aware insights. 4. **Publishing**: Compiling everything
into polished Quarto reports.

## Installation

This package is built with the help of
[{fusen}](https://thinkr-open.github.io/fusen/). You can install it from
GitHub with:

``` r
# Install from GitHub
devtools::install_github("matheus-hardt/unhcrreports")

# Install from local source
devtools::install(".")
```

## Quick Start

Generate a full report with a single command:

``` r
library(unhcrreports)

# Generate a Country Report (e.g., Brazil)
generate_report(
  type = "country", 
  name = "BRA", 
  year = 2024,
  gp_provider = "openai", # or "azure", "gemini", "ollama"
  gp_model = "gpt-4o-mini"
)
```

## AI Configuration

To enable AI-generated narratives, you need to set up an API key for a
supported LLM provider.

### Environment Setup

Set your API key as an environment variable in your `.Renviron` file or
session:

``` r
# For Google Gemini
Sys.setenv(GEMINI_API_KEY = "your_api_key_here")

# For OpenAI
Sys.setenv(OPENAI_API_KEY = "your_api_key_here")

# For Anthropic
Sys.setenv(ANTHROPIC_API_KEY = "your_api_key_here")

# For Azure OpenAI
# Sys.setenv(AZURE_OPENAI_ENDPOINT = "...")
# Sys.setenv(AZURE_OPENAI_API_KEY = "...")
```

### Local LLM (Ollama)

If you prefer to run a local model using Ollama:

1.  **Install Ollama**: Download from [ollama.com](https://ollama.com).
2.  **Pull a Model**: `bash ollama pull qwen2.5:32b`
3.  **Run Report**: Passing `gp_provider = "ollama"` and
    `gp_model = "qwen2.5:32b"`.

# Package index

## Main Functions

Primary functions for generating reports.

- [`generate_report()`](https://matheus-hardt.github.io/unhcrreports/reference/generate_report.md)
  : Generate Quarto HTML / PDF Country Factsheets in Batch

## AI Analysis Architecture

Functions that power the AI-generated narratives.

- [`generate_plot_story()`](https://matheus-hardt.github.io/unhcrreports/reference/generate_plot_story.md)
  : Generate Humanitarian Data Story from ggplot
- [`generate_section_summary()`](https://matheus-hardt.github.io/unhcrreports/reference/generate_section_summary.md)
  : Generate Section Summary from Plot Stories
- [`generate_report_summary()`](https://matheus-hardt.github.io/unhcrreports/reference/generate_report_summary.md)
  : Generate Report Executive Summary
- [`generate_description()`](https://matheus-hardt.github.io/unhcrreports/reference/generate_description.md)
  : Generate Plot Description with AI (Phase 3)
- [`clean_llm_response()`](https://matheus-hardt.github.io/unhcrreports/reference/clean_llm_response.md)
  : Clean LLM Response
- [`extract_structure()`](https://matheus-hardt.github.io/unhcrreports/reference/extract_structure.md)
  : Extract Plot Structure and Metadata (Phase 1)
- [`profile_data()`](https://matheus-hardt.github.io/unhcrreports/reference/profile_data.md)
  : Profile Plot Data (Phase 2)
- [`slugify()`](https://matheus-hardt.github.io/unhcrreports/reference/slugify.md)
  : slugify

# Articles

### Get Started

- [Get
  started](https://matheus-hardt.github.io/unhcrreports/articles/get-started.md):

### Technical Details

- [AI Analysis
  Architecture](https://matheus-hardt.github.io/unhcrreports/articles/ai-analysis-architecture.md):
